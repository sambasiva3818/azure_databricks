{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b62d1d42-e091-42b1-a86f-a0ce376b64af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b1f4c82-4f78-47e1-a85a-957eaa2342e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a62eeb76-8ede-4d75-8531-1bb87f795060",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df=spark.read.format(\"csv\").option(\"header\",\"true\").load(\"dbfs:/FileStore/employee.csv\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aba961af-0253-4d95-8283-0d5949448a79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b601c84-a00e-4588-a0b6-a9c39e74e7cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21bc78bd-6bef-4266-af3d-3996266d3565",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e1b1b797-c6e8-47f1-a4ab-1eef1620cc72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ea43273-9a5f-433a-8a2b-f78da6cbbf65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.schema\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c4777af-1cfe-4a56-8dfe-18269f2d2716",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Getting the list of columns AS StructField using fields attribute of a StructType object \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a3a6c9d-a576-4b74-bf95-3856b1b48fab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.schema.fields\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d74d6ccf-3b35-4f0b-bd8c-8b92c647a8b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.schema.names\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07f29cb5-2e7f-4553-932e-cb5ea5ad1741",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Returning the list of columns and datatypes as JSON using either jsonValue() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84b018d4-7309-403b-9360-0cb033c1e37e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.schema.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90c7957e-683f-4764-a4ff-ce1672e84b36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.schema.jsonValue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7256a1d-1ee7-4ba9-b83e-6144f8cda741",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create Custom Schema\n",
    "- approach-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "74807cd3-ba8e-4695-889e-e6c5394d5370",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"firstname\",StringType(),True),\n",
    "    StructField(\"middlename\",StringType(),True),\n",
    "    StructField(\"lastname\",StringType(),True),\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"salary\", IntegerType(), True)\n",
    "  ])\n",
    "\n",
    "# # approach-2\n",
    "# schema_def = StructType()\n",
    "\n",
    "# schema_def.add(\"firstname\",StringType(),True)\n",
    "# schema_def.add(\"middlename\",StringType(),True)\n",
    "# schema_def.add(\"lastname\",StringType(),True)\n",
    "# schema_def.add(\"id\", StringType(), True)\n",
    "# schema_def.add(\"gender\", StringType(), True)\n",
    "# schema_def.add(\"salary\", IntegerType(), True)\n",
    "\n",
    "# # approach-3\n",
    "\n",
    "# schema_def.add(\"firstname\",\"string\",True)\n",
    "# schema_def.add(\"middlename\",\"string\",True)\n",
    "# schema_def.add(\"lastname\",\"string\",True)\n",
    "# schema_def.add(\"id\", \"string\", True)\n",
    "# schema_def.add(\"gender\", \"string\", True)\n",
    "# schema_def.add(\"salary\", \"integer\", True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7456e012-188f-43d9-b24a-25efbf265a73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Nested structure schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf46f41b-253b-4313-9743-1c0025936761",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "structureData = [\n",
    "    ((\"James\",\"\",\"Smith\"),\"36636\",\"M\",3100),\n",
    "    ((\"Michael\",\"Rose\",\"\"),\"40288\",\"M\",4300),\n",
    "    ((\"Robert\",\"\",\"Williams\"),\"42114\",\"M\",1400),\n",
    "    ((\"Maria\",\"Anne\",\"Jones\"),\"39192\",\"F\",5500),\n",
    "    ((\"Jen\",\"Mary\",\"Brown\"),\"\",\"F\",-1)\n",
    "  ]\n",
    "structureSchema = StructType([\n",
    "        StructField('name', StructType([\n",
    "             StructField('firstname', StringType(), True),\n",
    "             StructField('middlename', StringType(), True),\n",
    "             StructField('lastname', StringType(), True)\n",
    "             ])),\n",
    "         StructField('id', StringType(), True),\n",
    "         StructField('gender', StringType(), True),\n",
    "         StructField('salary', IntegerType(), True)\n",
    "         ])\n",
    "\n",
    "df2 = spark.createDataFrame(data=structureData,schema=structureSchema)\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c72eeb0e-95db-46cf-9d17-86d64ee266ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "updatedDF = df2.withColumn(\"OtherInfo\",\n",
    "                           struct(col(\"id\").alias(\"identifier\"),\n",
    "                                  col(\"gender\").alias(\"gender\"),\n",
    "                                  col(\"salary\").alias(\"salary\"),\n",
    "    when(col(\"salary\").cast(IntegerType()) < 2000,\"Low\")\n",
    "      .when(col(\"salary\").cast(IntegerType()) < 4000,\"Medium\")\n",
    "      .otherwise(\"High\").alias(\"Salary_Grade\")\n",
    "  )).drop(\"id\",\"gender\",\"salary\")\n",
    "\n",
    "updatedDF.printSchema()\n",
    "updatedDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "945bb7c5-f622-4704-86a5-667c97d12d0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Array & Map\"\"\"\n",
    "arrayStructureSchema = StructType([\n",
    "    StructField('name', StructType([\n",
    "       StructField('firstname', StringType(), True),\n",
    "       StructField('middlename', StringType(), True),\n",
    "       StructField('lastname', StringType(), True)\n",
    "       ])),\n",
    "       StructField('hobbies', ArrayType(StringType()), True),\n",
    "       StructField('properties', MapType(StringType(),StringType()), True)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "19a7089a-b541-4d28-9650-50aaee5822c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, DateType, TimestampType\n",
    "# Add more types as needed\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"PandasToSpark\").getOrCreate()\n",
    "\n",
    "# Sample Pandas DataFrame (replace with your actual DataFrame)\n",
    "data = {'col_string': ['a', 'b', 'c'],\n",
    "        'col_int': [1, 2, 3],\n",
    "        'col_float': [1.1, 2.2, 3.3],\n",
    "        'col_date': ['2025-03-01', '2025-03-02', '2025-03-03'],\n",
    "        'col_timestamp': ['2025-03-01 10:00:00', '2025-03-02 11:00:00', '2025-03-03 12:00:00']}\n",
    "pandas_df = pd.DataFrame(data)\n",
    "\n",
    "# 1. Get column names and data types\n",
    "column_names = pandas_df.columns.tolist()\n",
    "column_types_pandas = pandas_df.dtypes.apply(lambda x: x.name).to_dict()\n",
    "\n",
    "# 2. Define Spark schema\n",
    "schema_list = []\n",
    "for col_name, col_type in column_types_pandas.items():\n",
    "    if col_type == 'object': # strings in pandas\n",
    "         schema_list.append(StructField(col_name, StringType(), True))\n",
    "    elif col_type == 'int64':\n",
    "        schema_list.append(StructField(col_name, IntegerType(), True))\n",
    "    elif col_type == 'float64':\n",
    "        schema_list.append(StructField(col_name, FloatType(), True))\n",
    "    elif col_type == 'datetime64[ns]':\n",
    "        schema_list.append(StructField(col_name, DateType(), True)) # or TimestampType\n",
    "    else:\n",
    "        schema_list.append(StructField(col_name, StringType(), True)) # default to string if type not recognized\n",
    "\n",
    "schema = StructType(schema_list)\n",
    "\n",
    "# 3. Create Spark DataFrame\n",
    "spark_df = spark.createDataFrame(pandas_df, schema=schema)\n",
    "\n",
    "# Print the schema of the Spark DataFrame\n",
    "spark_df.printSchema()\n",
    "\n",
    "# Show the first few rows of the Spark DataFrame\n",
    "spark_df.show()\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02-CreateSchema",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
